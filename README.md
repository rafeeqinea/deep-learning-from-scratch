# ğŸ§  Deep Learning From Scratch (2016 Mode)

A full manual rebuild of the Deep Learning Book (2016) by Ian Goodfellow, Yoshua Bengio, and Aaron Courville â€” line by line, concept by concept, from first principles.

No libraries.  
No frameworks.  
Only raw Python, matrix math, and full control.

---

## ğŸš€ Project Goal

To master deep learning by implementing every foundational concept from scratch â€” including:

- Linear Algebra
- Probability and Information Theory
- Calculus and Gradients
- Optimization (SGD, Momentum, etc.)
- Neural Network Layers
- Autograd and Backprop
- Training Loops and Loss Functions

> **By the end**: this repo becomes a working educational deep learning engine, built from zero.

---

## ğŸ§± Structure

```
deep-learning-from-scratch/
â”‚
â”œâ”€â”€ core/                  # All core logic (by chapter/topic)
â”‚   â”œâ”€â”€ linear_algebra/    # Matrix ops, norms, dot product, eigens
â”‚   â”œâ”€â”€ calculus/          # Derivatives, gradients
â”‚   â”œâ”€â”€ probability/       # Distributions, entropy
â”‚   â”œâ”€â”€ optimization/      # SGD, Adam, momentum
â”‚   â”œâ”€â”€ nn/                # Layers, activations, forward pass
â”‚   â”œâ”€â”€ autograd/          # Manual autograd engine (later)
â”‚
â”œâ”€â”€ demos/                 # Working examples using core code
â”œâ”€â”€ tests/                 # Tests for each module
â”œâ”€â”€ docs/                  # Notes and markdowns for theory
â”œâ”€â”€ notebooks/             # Optional Jupyter notebooks
â”œâ”€â”€ assets/                # Diagrams and visuals
â””â”€â”€ playground/            # Experimental scratchpad
```


---

## ğŸ“š Based On

- [Deep Learning (MIT Press)](https://www.deeplearningbook.org/)
- All math, code, and logic is faithful to the 2016 edition

---

## ğŸ§  Philosophy

This repo is not about speed or convenience.  
Itâ€™s about **understanding**, **control**, and **depth**.

Everything is built to learn:
- You will write dot products manually
- You will simulate gradients before using autograd
- You will debug matrix shapes and flows by hand

If you can build this, youâ€™ll never fear PyTorch or TensorFlow again.

---

## âœ… Progress

| Chapter                     | Status     |
|-----------------------------|------------|
| Linear Algebra              | ğŸŸ¢ Started |
| Probability & Information   | â¬œï¸ Pending |
| Calculus & Gradients        | â¬œï¸ Pending |
| Optimization                | â¬œï¸ Pending |
| Neural Networks             | â¬œï¸ Pending |
| Backprop / Autograd         | â¬œï¸ Pending |

---

## ğŸ“œ License

MIT License â€” use, fork, or remix freely.

---
